{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"width: 100%; clear: both;\">\n",
    "    <div style=\"float: left; width: 50%;\">\n",
    "        <img src=\"../figs/uoc_masterbrand_3linies_positiu.png\", align=\"left\">\n",
    "    </div>\n",
    "    <div style=\"float: right; width: 50%;\">\n",
    "        <p style=\"margin: 0; padding-top: 22px; text-align:right;\">M2.855 · Modelos avanzados de minería de datos</p>\n",
    "        <p style=\"margin: 0; text-align:right;\">Máster universitario en Ciencia de datos (<i>Data science</i>)</p>\n",
    "        <p style=\"margin: 0; text-align:right; padding-button: 100px;\">Estudios de Informática, Multimedia y Telecomunicación</p>\n",
    "    </div>\n",
    "</div>\n",
    "<div style=\"width:100%;\">&nbsp;</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ufIapjtVdA5H"
   },
   "source": [
    "# Ejemplo de combinación de clasificadores\n",
    "\n",
    "En este ejemplo compararemos el uso de árboles de decisión y modelos _ensemble_, en concreto, el modelo **Random Forest**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AZVJdfCtEnHP"
   },
   "source": [
    "## Introducción\n",
    "\n",
    "El _ensemble learning_ es una estrategia en la que se utiliza un grupo de modelos para resolver un problema mediante la combinación estratégica de varios modelos de aprendizaje automático en un solo modelo predictivo. \n",
    "\n",
    "En general, los métodos de ensemble se utilizan principalmente para mejorar la precisión del rendimiento general de un modelo y para combinar varios modelos diferentes, también conocidos como *aprendices básicos*, para predecir los resultados, en lugar de utilizar un solo modelo.\n",
    "\n",
    "¿Por qué entrenamos tantos clasificadores diferentes en lugar de uno solo? El uso de varios modelos para predecir el resultado final en realidad reduce la probabilidad de sopesar las decisiones tomadas por modelos deficientes (sobreentrenados, no debidamente ajustados, etc.).\n",
    "\n",
    "Cuanto más diversos sean estos aprendices básicos, más poderoso será el modelo final. \n",
    "\n",
    "Tengamos en cuenta que en cualquier modelo de aprendizaje automático, el error de generalización viene dado por la suma de cuadrados de bias + varianza + error irreductible. \n",
    "\n",
    "¡Los errores irreductibles son algo que está más allá de nosotros! No podemos reducirlos. \n",
    "\n",
    "Sin embargo, utilizando ensembles podemos reducir el sesgo (bias) y la varianza de un modelo. Esto reduce el error de generalización general.\n",
    "\n",
    "La **compensación de sesgo-varianza** es el punto de referencia más importante que diferencia un modelo robusto de uno inferior (entendamos por inferior un modelo no demasiado generalizable). \n",
    "\n",
    "Aunque no es una regla exacta, en el aprendizaje automático, los modelos que tienen un sesgo alto tienden a tener una varianza más baja y viceversa.\n",
    "\n",
    "Hemos estado hablando de bias y varianza. Pero veamos qué entendemos por sesgo de un modelo y por varianza de un modelo. \n",
    "\n",
    "1. **Sesgo**: el sesgo es un error que surge debido a suposiciones falsas realizadas en la fase de aprendizaje de un modelo. Un sesgo alto puede hacer que un algoritmo de aprendizaje omita información importante y correlaciones entre las variables independientes y las etiquetas de clase, por lo que no se ajusta al modelo.\n",
    "\n",
    "2. **Varianza**: la varianza nos dice qué tan sensible es un modelo a los pequeños cambios en los datos de entrenamiento. Es decir, cuánto cambia el modelo. Una gran variación en un modelo lo hará propenso al ruido aleatorio presente en el conjunto de datos, por lo que se ajustará demasiado al modelo.\n",
    "\n",
    "Para comprender con más detalle la compensación de sesgo y varianza en los modelos de aprendizaje automático, podéis consultar este [artículo](https://towardsdatascience.com/understanding-the-bias-variance-tradeoff-165e6942b229). \n",
    "\n",
    "Una vez llegados a este punto, podemos dividir los ensembles en cuatro categorías: \n",
    "\n",
    "1. **Bagging**: el bagging se utiliza principalmente para reducir la variación en un modelo. Un ejemplo simple de bagging es el algoritmo Random Forest.\n",
    "\n",
    "2. **Boosting**: el boosting se utiliza principalmente para reducir el sesgo en un modelo. Ejemplos de algoritmos de impulso son Ada-Boost, XGBoost, árboles de decisión mejorados por gradiente, etc.\n",
    "\n",
    "3. **Stacking**: el stacking se utiliza principalmente para aumentar la precisión de predicción de un modelo. Para implementar el stacking usaremos la biblioteca mlextend proporcionada por scikit learn.\n",
    "\n",
    "4. **Cascading**: esta clase de modelos son muy precisos. La conexión en cascada se usa principalmente en escenarios en los que no puede permitirse cometer un error. Por ejemplo, una técnica en cascada se usa principalmente para detectar transacciones fraudulentas con tarjetas de crédito."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datos\n",
    "\n",
    "Para este ejercicio usaremos el dataset *diabetes.csv*. Este conjunto de datos es original del Instituto Nacional de Diabetes y Enfermedades Digestivas y Renales. El objetivo de este dataset es predecir, basándonos en las mediciones de diagnóstico, si un paciente tiene diabetes.\n",
    "\n",
    "En particular, todos los pacientes aquí son mujeres de al menos 21 años, de ascendencia india Pima.\n",
    "\n",
    "El dataset contiene la siguiente información\n",
    "\n",
    "- Embarazos: número de embarazos\n",
    "- Glucosa: concentración de glucosa en plasma a 2 horas en una prueba de tolerancia a la glucosa oral\n",
    "- Presión arterial: presión arterial diastólica (mm Hg)\n",
    "- SkinThickness: espesor del pliegue cutáneo del tríceps (mm)\n",
    "- Insulina: insulina sérica de 2 horas (mu U / ml)\n",
    "- IMC: índice de masa corporal (peso en kg / (altura en m) ^ 2)\n",
    "- DiabetesPedigreeFunction: función del pedigrí de la diabetes\n",
    "- Edad: edad (años)\n",
    "- Resultado (variable objetivo): variable de clase (0 o 1) \n",
    "\n",
    "En la primera parte de este ejemplo veremos la combinación de clasificadores en paralelo mediante las técnicas de **_Bagging_** y **_Boosting_**.\n",
    "\n",
    "Para empezar, veamos cómo es el dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "id": "QVu-lXoK_L_d",
    "outputId": "c37bf1a4-895a-492f-e436-b806a0ed0bc3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hay 768 filas y 9 columnas\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "763           10      101             76             48      180  32.9   \n",
       "764            2      122             70             27        0  36.8   \n",
       "765            5      121             72             23      112  26.2   \n",
       "766            1      126             60              0        0  30.1   \n",
       "767            1       93             70             31        0  30.4   \n",
       "\n",
       "     DiabetesPedigreeFunction  Age  Outcome  \n",
       "763                     0.171   63        0  \n",
       "764                     0.340   27        0  \n",
       "765                     0.245   30        0  \n",
       "766                     0.349   47        1  \n",
       "767                     0.315   23        0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes = pd.read_csv('../data/diabetes.csv')\n",
    "\n",
    "nRow, nCol = diabetes.shape\n",
    "print(f'Hay {nRow} filas y {nCol} columnas')\n",
    "diabetes.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jTF33Hwv6fe-"
   },
   "source": [
    "Para poder probar varios modelos, primero vamos a dividir el dataset entre _train_ y _test_.\n",
    "\n",
    "Para que todos obtengáis los mismos resultados y poder comentar dudas por el foro, fijaremos la seed para obtener los mismos datasets de train y test.\n",
    "\n",
    "Como en este ejercicio trataremos *stacking* y *cascading*, y ambos se aplican sobre el conjunto de test, haremos un *split* del 60 % para tener un poco más de base al aplicar estas dos técnicas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "D97ORws3_-_5"
   },
   "outputs": [],
   "source": [
    "myseed= 38\n",
    "X = diabetes.drop(columns = 'Outcome')\n",
    "y = diabetes['Outcome']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.6, random_state=myseed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "80Jw5L8A6fbu"
   },
   "source": [
    "## Combinación paralela de clasificadores\n",
    "\n",
    "### 1. Árboles de decisión\n",
    "\n",
    "Para poder comparar el aumento de  *performance* obtenido a medida que vamos aplicando técnicas nuevas, utilizaremos como  *baseline* un simple árbol de decisión."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3daM2M6K6fYt"
   },
   "source": [
    "A continuación, entrenaremos un árbol de decisión sobre el conjunto de datos de train con profundidad máxima de 3 niveles (aplicaremos la misma restricción en las siguientes secciones), y evaluaremos sobre test y calcularemos su precisión aplicando validación cruzada con 5 conjuntos.\n",
    "   \n",
    "<u>Más información</u>: \n",
    "- [*cross_val_score*](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html)\n",
    "- [*cross validation*](http://scikit-learn.org/stable/modules/cross_validation.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3pPRsy4NB8rW",
    "outputId": "241289af-08fb-49e7-fa8f-3072e312020b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión media obtenida con CV: 71.04 +/- 4.82 %\n"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(max_depth=3, random_state=myseed)\n",
    "\n",
    "cvscores = cross_val_score(clf, X_train, y_train, cv=5)\n",
    "print(\"Precisión media obtenida con CV: {:.2f} +/- {:.2f} %\".format(np.mean(cvscores)*100, np.std(cvscores)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G8NMROHqCJn3",
    "outputId": "f843b664-e5f5-4129-e3ca-6d9ee3c1925c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7462039045553145"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)\n",
    "y_pred_tree = clf.predict(X_test)\n",
    "accuracy_score(y_pred_tree, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lney04IhUuiQ"
   },
   "source": [
    "Obtenemos una precisión en test no demasiado alta, un poco por debajo de la de train (esto puede variar dependiendo de los datasets de train y test). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UrUZJBCo6fTA"
   },
   "source": [
    "### 2. *Bagging*\n",
    "\n",
    "La idea central del bagging es usar réplicas del conjunto de datos original y usarlas para entrenar diferentes clasificadores.\n",
    "\n",
    "Crearemos subconjuntos muestreando aleatoriamente un montón de puntos del conjunto de datos de entrenamiento con reemplazo. \n",
    "\n",
    "Ahora entrenaremos clasificadores individuales en cada uno de estos subconjuntos bootstrap. \n",
    "\n",
    "Cada uno de estos clasificadores base predecirá la etiqueta de clase para un problema dado. Aquí es donde combinamos las predicciones de todos los modelos base. Esta parte se llama etapa de agregación. Es por eso que encontraréis los ensembles bagging por el nombre de ensembles de agregación. \n",
    "\n",
    "Por lo general, se usa un voto de mayoría simple en un sistema de clasificación y se toma la media de todas las predicciones para los modelos de regresión para combinar todos los clasificadores base en un solo modelo y proporcionar el resultado final del modelo de conjunto. \n",
    "\n",
    "Un ejemplo simple de tal enfoque es el algoritmo Random Forest. El bagging reduce la alta variación (varianza) de un modelo, reduciendo así el error de generalización. Es un método muy eficaz, especialmente cuando tenemos datos muy limitados como pudiera ser nuestro caso. \n",
    "\n",
    "Mediante el uso de muestras de bootstrap, podemos obtener una estimación agregando las puntuaciones de muchas muestras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8RUXUdU16fP3"
   },
   "source": [
    "**¿Cómo haríamos el bagging?**\n",
    "\n",
    "Supongamos que tenemos un conjunto de entrenamiento que contiene 100.000 puntos de datos. \n",
    "\n",
    "Crearíamos N subconjuntos muestreando al azar 50K puntos de datos para cada subconjunto. \n",
    "\n",
    "Cada uno de estos N subconjuntos se utilizará para entrenar N clasificadores diferentes. \n",
    "\n",
    "En la etapa de agregación, todas estas N predicciones se combinarán en un solo modelo, también llamado metaclasificador. \n",
    "\n",
    "De los 100.000 puntos presentes originalmente en el conjunto de datos, si eliminamos 1000 puntos, el impacto que tendrá en los conjuntos de datos muestreados será muy inferior. \n",
    "\n",
    "Si pensamos intuitivamente, es posible que algunos de estos 1000 puntos no estén presentes en todos los conjuntos de datos muestreados y, por lo tanto, la cantidad de puntos que se eliminarán de cada conjunto de datos muestreados será muy inferior. ¡Incluso cero en algunos casos! En resumen, el impacto de eliminar 1000 puntos de este tipo será en realidad menor en los clasificadores base, lo que reducirá la variación en un modelo y lo hará más sólido. \n",
    "\n",
    "La varianza no es más que sensibilidad al ruido, como hemos comentado anteriormente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z6rzIA586fMm"
   },
   "source": [
    "Seguidamente, entrenaremos un _**Random Forest**_ sobre el conjunto de datos de _train_ con <b>20 árboles</b> de decisión y <b>profundidad máxima de 3</b> niveles, y evaluaremos sobre test y calcularemos su precisión aplicando validación cruzada con 5 conjuntos.\n",
    "\n",
    "<u>Más información</u>: \n",
    "- [*RandomForestClassifier*](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I2ZC4x-mUXQu",
    "outputId": "47a70c8b-546e-4dc2-ca29-a4734a2b005f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión media obtenida con CV: 73.29 +/- 1.57 %\n"
     ]
    }
   ],
   "source": [
    "clf = ensemble.RandomForestClassifier(n_estimators=20, max_depth=3, random_state=myseed)\n",
    "\n",
    "cvscores = cross_val_score(clf, X_train, y_train, cv=5)\n",
    "print(\"Precisión media obtenida con CV: {:.2f} +/- {:.2f} %\".format(np.mean(cvscores)*100, np.std(cvscores)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dsP4btQ4Umbp",
    "outputId": "ca0f7a1c-8e73-4015-9f05-98fba510ebe5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7418655097613883"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)\n",
    "y_pred_random_forest = clf.predict(X_test)\n",
    "accuracy_score(y_pred_random_forest, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KvoCMkkuVMHF"
   },
   "source": [
    "Obtenemos una buena precisión en test, un poco por debajo de la de train. También notamos una mejora (aunque leve) respecto a un simple árbol de decisión."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UpMyZMpJZdE6"
   },
   "source": [
    "### 3. *Boosting*\n",
    "\n",
    "El _boosting_ se utiliza para convertir a los clasificadores de base débil en fuertes. Los clasificadores débiles generalmente tienen una correlación muy débil con las etiquetas de clase verdaderas y los clasificadores fuertes tienen una correlación muy alta entre el modelo y las etiquetas de clase verdaderas.\n",
    "\n",
    "El _boosting_ capacita a los clasificadores débiles de manera iterativa, cada uno tratando de corregir el error cometido por el modelo anterior. Esto se logra entrenando un modelo débil en todos los datos de entrenamiento, luego construyendo un segundo modelo que tiene como objetivo corregir los errores cometidos por el primer modelo. Luego construimos un tercer modelo que intenta corregir los errores cometidos por el segundo modelo y así sucesivamente. Los modelos se agregan de forma iterativa hasta que el modelo final ha corregido todos los errores cometidos por todos los modelos anteriores.\n",
    "\n",
    "Cuando se agregan los modelos en cada etapa, se asignan algunos pesos al modelo que está relacionado con la precisión del modelo anterior. Después de agregar un clasificador débil, los pesos se vuelven a ajustar. Los puntos clasificados incorrectamente reciben pesos más altos y los puntos clasificados correctamente reciben pesos más bajos. Este enfoque hará que el siguiente clasificador se centre en los errores cometidos por el modelo anterior.\n",
    "\n",
    "El boosting reduce el error de generalización tomando un modelo de alto bias y baja varianza y reduciendo el bias en un nivel significativo. Recuerda, el bagging reduce la varianza. Al igual que el bagging, el boosting también nos permite trabajar con modelos de clasificación y regresión. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DRIgEhOxZtVx"
   },
   "source": [
    "Entrenaremos un _**Gradient Boosting**_ sobre el conjunto de datos de _train_ con 20 árboles de decisión y profundidad máxima de 3 niveles. A continuación, evaluaremos sobre test y calcularemos su precisión aplicando validación cruzada con 5 conjuntos.\n",
    "\n",
    "<u>Más información</u>: \n",
    "- [*GradientBoostingClassifier*](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZQjN6vxtaTWk",
    "outputId": "0c1fd372-4e23-4c9f-e568-814e6fedb16f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión media obtenida con CV: 72.00 +/- 4.23 %\n"
     ]
    }
   ],
   "source": [
    "clf = ensemble.GradientBoostingClassifier(n_estimators=20, max_depth=3, random_state=myseed)\n",
    "\n",
    "cvscores = cross_val_score(clf, X_train, y_train, cv=5)\n",
    "print(\"Precisión media obtenida con CV: {:.2f} +/- {:.2f} %\".format(np.mean(cvscores)*100, np.std(cvscores)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MAlyq1qAaa6k",
    "outputId": "486614b1-8f0d-4a47-dbc5-b37676a429d9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7635574837310195"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)\n",
    "y_pred_gradient_boosting = clf.predict(X_test)\n",
    "accuracy_score(y_pred_gradient_boosting, y_test)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "20211_M2.855_PEC4_Solucion.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Tabla de contenidos",
   "title_sidebar": "Tabla de contenidos",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "284.75px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "144.391px",
    "left": "1478px",
    "right": "20px",
    "top": "126px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
